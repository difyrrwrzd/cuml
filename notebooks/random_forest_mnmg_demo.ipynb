{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests Multi-node, Multi-GPU demo\n",
    "\n",
    "The experimental cuML multi-node, multi-GPU (MNMG) implementation of random forests leverages Dask to do embarrassingly-parallel model fitting. For a random forest with `N` trees being fit by `W` workers, each worker will build `N / W` trees. During inference, predictions from all `N` trees will be combined.\n",
    "\n",
    "The caller is responsible for partitioning the data efficiently via Dask. To build an accurate model, it's important to ensure that each worker has a representative chunk of the data. This can come by distributing the data evenly after ensuring that it is well shuffled. Or, given sufficient memory capacity, the caller can replicate the data to all workers. This approach will most closely simulate the single-GPU building approach.\n",
    "\n",
    "**Note:** cuML 0.9 contains the first, experimental preview release of the MNMG random forest model. The API is subject to change in future releases, and some known limitations remain (listed in the documentation).\n",
    "\n",
    "For more information on MNMG Random Forest models, see the documentation:\n",
    " * https://rapidsai.github.io/projects/cuml/en/stable/api.html#cuml.dask.ensemble.RandomForestClassifier\n",
    " * https://rapidsai.github.io/projects/cuml/en/stable/api.html#cuml.dask.ensemble.RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import dask_cudf\n",
    "import pytest\n",
    "import rmm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cuml.dask.ensemble import RandomForestClassifier as cuRFC_mg\n",
    "from cuml.dask.ensemble import RandomForestRegressor as cuRFR_mg\n",
    "from cuml.dask.common import utils as dask_utils\n",
    "\n",
    "from dask.array import from_array\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from dask.distributed import Client\n",
    "\n",
    "\n",
    "def _prep_training_data(c, X_train, y_train, partitions_per_worker):\n",
    "    workers = c.has_what().keys()\n",
    "    n_partitions = partitions_per_worker * len(workers)\n",
    "    X_cudf = cudf.DataFrame.from_pandas(pd.DataFrame(X_train))\n",
    "    X_train_df = dask_cudf.from_cudf(X_cudf, npartitions=n_partitions)\n",
    "\n",
    "    y_cudf = np.array(pd.DataFrame(y_train).values)\n",
    "    y_cudf = y_cudf[:, 0]\n",
    "    y_cudf = cudf.Series(y_cudf)\n",
    "    y_train_df = \\\n",
    "        dask_cudf.from_cudf(y_cudf, npartitions=n_partitions)\n",
    "\n",
    "    X_train_df, \\\n",
    "        y_train_df = dask_utils.persist_across_workers(c,\n",
    "                                                       [X_train_df,\n",
    "                                                        y_train_df],\n",
    "                                                       workers=workers)\n",
    "    return X_train_df, y_train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cuda import LocalCUDACluster\n",
    "\n",
    "cluster = LocalCUDACluster(protocol=\"tcp\", scheduler_port=8786)\n",
    "c = Client(cluster)\n",
    "partitions_per_worker = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X, y = make_regression(n_samples=12500000, n_features=20,\n",
    "                       n_informative=10, random_state=123)\n",
    "\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=1000)\n",
    "\n",
    "cu_rf_params = {\n",
    "    'n_estimators': 10,\n",
    "    'max_depth': 16,\n",
    "    'n_bins': 16,\n",
    "}\n",
    "\n",
    "workers = c.has_what().keys()\n",
    "n_partitions = partitions_per_worker * len(workers)\n",
    "\n",
    "X_cudf = cudf.DataFrame.from_pandas(pd.DataFrame(X_train))\n",
    "X_train_df = \\\n",
    "    dask_cudf.from_cudf(X_cudf, npartitions=n_partitions)\n",
    "\n",
    "y_cudf = np.array(pd.DataFrame(y_train).values)\n",
    "y_cudf = y_cudf[:, 0]\n",
    "y_cudf = cudf.Series(y_cudf)\n",
    "y_train_df = \\\n",
    "    dask_cudf.from_cudf(y_cudf, npartitions=n_partitions)\n",
    "X_cudf_test = cudf.DataFrame.from_pandas(pd.DataFrame(X_test))\n",
    "X_test_df = \\\n",
    "    dask_cudf.from_cudf(X_cudf_test, npartitions=n_partitions)\n",
    "\n",
    "X_train_df, y_train_df = dask_utils.persist_across_workers(\n",
    "    c, [X_train_df, y_train_df], workers=workers)\n",
    "\n",
    "cu_rf_mg = cuRFR_mg(**cu_rf_params)\n",
    "cu_rf_mg.fit(X_train_df, y_train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cu_rf_mg_predict = cu_rf_mg.predict(X_test_df).compute()\n",
    "cu_rf_mg_predict = cp.asnumpy(cp.array(cu_rf_mg_predict))\n",
    "\n",
    "acc_score = r2_score(cu_rf_mg_predict, y_test)\n",
    "\n",
    "assert acc_score >= 0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
