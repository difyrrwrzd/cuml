//#include "glm/lr_lasso.h"
#include <gtest/gtest.h>
#include <linalg/cublas_wrappers.h>
#include <linalg/cusolver_wrappers.h>

#include "test_utils.h"
#include <cuda_utils.h>
//#include "ml_utils.h"

#include <math.h>
#include <stdlib.h>

#include <linalg/transpose.h>
#include <glm/glm_batch_gradient.h>
#include <glm/gradient_descent.h>
#include <glm/lbfgs.h>
#include <glm/qn_c.h>

template <typename T, typename LossFunction>
int fit_dispatch(T *X, T *y, int N, int D, bool has_bias, T l1, T l2,
                 int max_iter, T grad_tol, T value_rel_tol,
                 int linesearch_max_iter, int lbfgs_memory, int verbosity,
                 T *w0, // initial value and result
                 T *fx, int *num_iters);

namespace ML {
namespace GLM {

using namespace MLCommon;

struct QuasiNewtonTest : ::testing::Test {
  cublasHandle_t cublas;
  void SetUp() { cublasCreate(&cublas); }

  void TearDown() {}
};

struct InputSpec {
  int n_row;
  int n_col;
  bool fit_intercept;
};

template <class T> struct DevUpload {
  SimpleMat<T> devX;
  SimpleVec<T> devY;
  DevUpload(const InputSpec &inSpec, const T *x, const T *y,
                        cublasHandle_t &cublas)
      : devX(inSpec.n_row, inSpec.n_col), devY(inSpec.n_row) {

    SimpleMat<T> devXtmp(inSpec.n_row, inSpec.n_col);

    updateDevice(devX.data, x, inSpec.n_row * inSpec.n_col);
    updateDevice(devY.data, y, inSpec.n_row);
  }
};
template <typename T>
T run(InputSpec &in, DevUpload<T> &devUpload, T l1) {
  int N = in.n_row, D = in.n_col;
  bool has_bias = in.fit_intercept;
  T l2 = 0.0;
  SimpleVec<T> w(D + has_bias);
  int max_iter = 100;
  T grad_tol = 1e-5;
  T value_rel_tol = 1e-5;
  int linesearch_max_iter = 40;
  int lbfgs_memory = 2;
  int verbosity = 1;
  int num_iters = 0;
  T lassoObjective = 0;
  fit_dispatch<T, SquaredLoss<T, ROW_MAJOR>>(devUpload.devX.data, devUpload.devY.data, N, D, has_bias,
                                  l1, l2, max_iter, grad_tol, value_rel_tol,
                                  linesearch_max_iter, lbfgs_memory, verbosity,
                                  w.data, // initial value and result
                                  &lassoObjective, &num_iters);

  return lassoObjective;
}

TEST_F(QuasiNewtonTest, QN_Lasso_Test_DesignMatrix_5_2_and_alpha_eq_0) {
  {
    // =====================AUTOGENERATED CODE
    // START===============================
    //  CODE IS GENERATED VIA 'Test_DesignMatrix_5_2_and_alpha_eq_0.py' SCRIPT
    //  Features Marix (Design Matrix)
    double X[5][2] = {{0.474571, 0.657473},
                      {0.142600, 0.010860},
                      {0.274048, 0.810348},
                      {0.601457, 0.558190},
                      {0.145303, 0.440055}};

    // Targets (Labels)

    double Y[5] = {6.663885, 0.500833, 7.400750, 6.210172, 2.916327};
    // Objective value obtained during using this model for fitting <class
    // 'sklearn.linear_model.coordinate_descent.Lasso'>
    double kObjectiveValueFromSkLearn = 0.094153;
    double kAlphaSkLearn = 0.000000;
    // =====================AUTOGENERATED CODE
    // END=================================

    InputSpec in;
    in.n_row = 5;
    in.n_col = 2;
    in.fit_intercept = false;

    DevUpload<double> devUpload(in, &X[0][0], &Y[0], cublas);

    double lassoObjective = run(in, devUpload, kAlphaSkLearn);

    const double kObjectiveTolerance = 1e-5;
    EXPECT_TRUE(fabs(lassoObjective - kObjectiveValueFromSkLearn) <
                kObjectiveTolerance)
        << "Check that result is the same as for SkLearn";
  }
}

TEST_F(QuasiNewtonTest, QN_Lasso_Test_DesignMatrix_4_7_and_alpha_eq_2) {
  {
    // =====================AUTOGENERATED CODE
    // START===============================
    //  CODE IS GENERATED VIA 'Test_DesignMatrix_4_7_and_alpha_eq_2.py' SCRIPT
    //  Features Marix (Design Matrix)
    double X[4][7] = {
        {0.474571, 0.657473, 0.666410, 0.142600, 0.010860, 0.374754, 0.274048},
        {0.690593, 0.601457, 0.558190, 0.661321, 0.145303, 0.440055, 0.162267},
        {0.058824, 0.818820, 0.074610, 0.686946, 0.337000, 0.404614, 0.842403},
        {0.060785, 0.915034, 0.508926, 0.090978, 0.987134, 0.946713, 0.112528}};

    // Targets (Labels)

    double Y[4] = {7.792896, 6.285808, 6.629604, 12.927304};
    // Objective value obtained during using this model for fitting <class
    // 'sklearn.linear_model.coordinate_descent.Lasso'>
    double kObjectiveValueFromSkLearn = 21.000897;
    double kAlphaSkLearn = 2.000000;
    // =====================AUTOGENERATED CODE
    // END=================================

    InputSpec in;
    in.n_row = 4;
    in.n_col = 7;
    in.fit_intercept = false;

    DevUpload<double> devUpload(in, &X[0][0], &Y[0], cublas);

    double lassoObjective = run(in, devUpload, kAlphaSkLearn);

    const double kObjectiveTolerance = 1e-5;
    EXPECT_TRUE(fabs(lassoObjective - kObjectiveValueFromSkLearn) <
                kObjectiveTolerance)
        << "Check that result is the same as for SkLearn";
  }
}

TEST_F(QuasiNewtonTest, QN_Lasso_Test_DesignMatrix_10_2_and_alpha_eq_half) {
  {
    // =====================AUTOGENERATED CODE
    // START===============================
    //  CODE IS GENERATED VIA 'Test_DesignMatrix_10_2_and_alpha_eq_half.py'
    //  SCRIPT Features Marix (Design Matrix)
    double X[10][2] = {{0.474571, 0.657473}, {0.142600, 0.010860},
                       {0.274048, 0.810348}, {0.601457, 0.558190},
                       {0.145303, 0.440055}, {0.905973, 0.058824},
                       {0.074610, 0.686946}, {0.404614, 0.842403},
                       {0.060785, 0.915034}, {0.090978, 0.987134}};

    // Targets (Labels)

    double Y[10] = {8.100475,  1.791319, 6.249202, 9.296194, 2.257921,
                    12.022210, 2.586373, 5.814886, 3.513386, 5.354221};
    // Objective value obtained during using this model for fitting <class
    // 'sklearn.linear_model.coordinate_descent.Lasso'>
    double kObjectiveValueFromSkLearn = 7.303088;
    double kAlphaSkLearn = 0.500000;
    // =====================AUTOGENERATED CODE
    // END=================================

    InputSpec in;
    in.n_row = 10;
    in.n_col = 2;
    in.fit_intercept = false;

    DevUpload<double> devUpload(in, &X[0][0], &Y[0], cublas);

    double lassoObjective = run(in, devUpload, kAlphaSkLearn);

    const double kObjectiveTolerance = 1e-5;
    EXPECT_TRUE(fabs(lassoObjective - kObjectiveValueFromSkLearn) <
                kObjectiveTolerance)
        << "Check that result is the same as for SkLearn";
  }
}
} // namespace GLM
} // end namespace ML
